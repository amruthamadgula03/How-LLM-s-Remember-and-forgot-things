🧠 How LLMs Remember and Forget Things — Context Window Simulation

This Streamlit project demonstrates how Large Language Models (LLMs) like GPT handle short-term memory using context windows. It visually shows how an AI "remembers" recent inputs and "forgets" older ones once the memory limit is reached.
🚀 Features
🧩 Simulates how LLMs manage limited context (token window)
🔁 Demonstrates how older messages get dropped as new ones come in
🧠 Interactive slider to adjust memory window size
💬 Real-time chat simulation to visualize forgetting
📘 Educational explanation included for beginners

🏗️ Tech Stack
Python 3.9+
Streamlit for interactive visualization

🧠 What You’ll Learn
How context windows work in LLMs
Why large models like GPT can “forget” earlier messages
The concept of token limits and context truncation
How to simulate memory management in a simple way
