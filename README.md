ğŸ§  How LLMs Remember and Forget Things â€” Context Window Simulation

This Streamlit project demonstrates how Large Language Models (LLMs) like GPT handle short-term memory using context windows. It visually shows how an AI "remembers" recent inputs and "forgets" older ones once the memory limit is reached.
ğŸš€ Features
ğŸ§© Simulates how LLMs manage limited context (token window)
ğŸ” Demonstrates how older messages get dropped as new ones come in
ğŸ§  Interactive slider to adjust memory window size
ğŸ’¬ Real-time chat simulation to visualize forgetting
ğŸ“˜ Educational explanation included for beginners

ğŸ—ï¸ Tech Stack
Python 3.9+
Streamlit for interactive visualization

ğŸ§  What Youâ€™ll Learn
How context windows work in LLMs
Why large models like GPT can â€œforgetâ€ earlier messages
The concept of token limits and context truncation
How to simulate memory management in a simple way
